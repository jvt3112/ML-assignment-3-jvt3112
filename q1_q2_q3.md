## Q1
<br/>
---------Unregularised Normal Fit----------
<br/>
0.9437609841827768
<br/>
---------Unregularised Autograd Fit----------
<br/>
0.9437609841827768
<br/>
---------3 KFold----------
<br/>
Overall accuracy of Breast Cancer Dataset on 3 Fold:  93.84851016429963
<br/>
--------- Fit with 2 features----------
<br/>
0.8154657293497364
<br/>
(decision boundry plot attached with q1_decision_boundry.png)
<br/>

## Q2
<br/> 
----------Autograd Fit L1 regularised------------
<br/>
0.9630931458699473
<br/>
----------Autograd Fit L2 regularised---------------
<br/>
0.9595782073813708
<br/>

---------L1 Hyperparamter Testing---------
<br/>
[0.9473684210526315, 0.9631578947368421, 0.9894179894179894] [0.01, 0.02, 0.11]
<br/>

---------L2 Hyperparamter Testing---------
<br/>
[0.9473684210526315, 0.9578947368421052, 0.9894179894179894] [0.03, 0.05, 0.02]
<br/>

--------------
Most important features in L1 can be inferred by checking out which theta takes more time to converge as it forms the basis for the significant increase in accuracy for the samples. 
<br/>


## Q3
<br/> 
----------MultiClass Normal Fit------------
<br/>
0.889259877573734
<br/>
----------MultiClass Autograd Fit------------
<br/>
0.889259877573734
<br/>
----------Confusion Matrix------------
<br/>
[[170   0   0   0   2   0   6   0   0   0]<br/>
 [  0 160   3   0   0   0   3   0   0  16]<br/>
 [  1   8 164   0   0   0   0   1   0   3]<br/>
 [  0  16   3 142   0   0   0   1   3  18]<br/>
 [  0  11   0   0 165   0   2   1   2   0]<br/>
 [  0   3   0   0   2 140   4   0   0  33]<br/>
 [  0   5   0   0   0   0 176   0   0   0]<br/>
 [  0  11   3   0   8   2   0 148   6   1]<br/>
 [  0  48   3   0   0   2   1   0 105  15]<br/>
 [  0   8   0   0   3   2   0   3   1 163]]
 <br/>
-- Most confusing digit is that 8 because from the confusion matrix you can see that in the row corresponding to 8 it has been classified 1 as 48 times

-- Most easiest to predict is the 0,6

<br/>
----------PCA Analysis------------
<br/>
From scatter plot we can infer that for data points representing 8 they are very scattered thus and also high chance if mistaking it for some another label, as we already validated it from confusion matrix. Also clusters of 0,6 are not very scattred thus they are the easiest points to predict. Thereby decreasing chances of mistaking it for other labels.
